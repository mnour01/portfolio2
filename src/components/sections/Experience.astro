---
import Section from '../ui/Section.astro';
import Card from '../ui/Card.astro';

interface Experience {
  company: string;
  logo: string;
  position: string;
  period: string;
  description: string;
  tasks?: string[];
  tech?: string[];
}

const experiences: Experience[] = [
  {
    company: 'Eni - Plénitude',
    logo: '/assets/svgs/ENI.jpg',
    position: 'Lead Data',
    period: 'Oct 2023 - Actuel',
    description: 'Responsable de l’analyse, de l’automatisation et du pilotage de projets data visant à améliorer l’efficacité opérationnelle des processus B2B/B2C, en lien étroit avec les équipes métiers et les prestataires externes.',
    tasks: [
      'Implémentation de modules de gestion des activitées et la performance des équipes de vente et SAV, avec des dashboards interactifs',
      "Cadrage des chantiers d'automatisation des Runs afin de réduire la charge de l'équipe data.",
      'Analyse et optimisation du processus d’activation des contrats B2B, avec mise en place de KPI de suivi.',
      'Automatisation de l’intégration CRM (SAP) des nouveaux contrats multi-sites, réduisant la charge opérationnelle.',
      'Développement d’un modèle de prévision des appels clients (séries temporelles : Prophet) pour ajuster les budgets prestataires.',
      'Supervision de la migration des traitements automatisés vers Azure et amélioration de la fiabilité des dashboards.',
      'Proposition d’architectures et de solutions techniques robustes, adaptées aux enjeux métiers, en tant que référent technique et garant des bonnes pratiques au sein de l’équipe BI.',
      'Pilotage de projets data, coordination entre les équipes techniques et métiers, et appui à la mise en œuvre de solutions techniques adaptées.'

    ],
    tech: ['Azure Databriks', 'Python', 'R', 'Tableau', 'Power BI', 'SAP', 'SQL', 'PostgreSQL', 'Hive', 'Jira', 'Git', 'Automatisation', 'Supervision Data', 'Pilotage projet']
  },
  {
    company: 'EDF',
    logo: '/assets/svgs/EDF.png',
    position: 'Data Scientist',
    period: 'Oct 2021 - Oct 2023',
    description: 'Chargé de la production de Datamarts stratégiques, du développement de dashboards interactifs, et de la mise en œuvre de modèles de machine learning explicables pour soutenir les activités commerciales du marché d’affaires.',
    tasks: [
      'Production et maintenance de Datamarts clients PRO à partir de données Oracle et Hive, devenus la référence analytique pour les équipes data.',
      'Développement d’un modèle de prédiction du churn en Python (Random Forest) et enrichissement de l’interprétabilité via TreeInterpreter, afin de garantir la transparence algorithmique et la conformité éthique.',
      'Développement d’une application R Shiny de cartographie interactive des projets EDF en France, basée sur Leaflet et OpenStreetMap, avec pop-ups dynamiques intégrant messages, documents, photos et vidéos cliquables pour une expérience utilisateur immersive.',
      'Mise en place d’un tableau de bord R Shiny de suivi du déploiement des compteurs Linky et Gazpar chez les clients PART/PRO sur l’ensemble du territoire français, permettant la visualisation des données et le suivi des objectifs de déploiement.',
      'Intégration de Matomo dans les interfaces Shiny et Dash pour assurer le suivi des parcours utilisateurs au travers de KPI de fréquentation.' ,
      'Mise en place d’un monitoring des modèles via la librairie Eurybia pour surveiller le data drift et la stabilité des prédictions.'
    ],
    tech: ['Python', 'R', 'SQL', 'Hive', 'Oracle', 'Shiny', 'Dash', 'HTML', 'CSS', 'Matomo' ,'Linux', 'Docker', 'Gitlab', 'CI/CD', 'Kanban', 'Jira', 'Confluence' ,'RGPD']
  },
  {
    company: 'Bouygues Télécom',
    logo: '/assets/svgs/BYTEL.PNG',
    position: 'Data Analyst',
    period: 'Mars 2018 - Oct 2021',
    description: "Dans un contexte d'amélioration continue de la qualité de service fixe, la mission consistait à exploiter les données techniques issues des équipements réseau (xDSL/FTTH) pour concevoir des indicateurs avancés de performance, détecter de manière proactive les dégradations de service et optimiser les configurations techniques à grande échelle. L’objectif était de permettre une prise de décision plus réactive, de réduire les appels SAV, et d’automatiser le pilotage des actions correctives au sein d’un environnement Big Data.",
    tasks: [
      'Conception d’un indicateur de qualité réseau innovant (KPI de « continuité xDSL »), mesurant en temps réel les coupures de service avec une granularité à la seconde. Ce KPI a permis une meilleure réactivité opérationnelle et une détection fine des incidents, grâce au croisement de données techniques issues de multiples sources (logs équipements, métriques de supervision, etc.)',
      'Développement d’algorithmes d’aide à la décision visant à optimiser le débit des lignes xDSL stables, à travers une analyse itérative des données historiques et temps réel. Ces modèles ont permis de recommander des modifications techniques ciblées (changement de profil, réglages de marge SNR) afin d’améliorer les performances sans compromettre la stabilité.',
      'Industrialisation de pipelines de données sous PySpark, pour le traitement en volume des données réseau, et l’alimentation automatisée de tableaux de bord de supervision, intégrant des systèmes d’alerte proactive en cas de dégradation des indicateurs clés.',
      'Analyse d’impact des évolutions techniques (nouveaux firmwares FTTH, mise à jour d’équipements réseau) sur les KPI opérationnels via une chaîne de traitement automatisée, permettant de valider l’effet des déploiements et d’objectiver les décisions techniques.',
      'Participation à la validation et au déploiement de la plateforme Big Data sous Cloudera, avec une contribution active à l’intégration de nouveaux modules de traitement tout en veillant à la conformité aux normes de gouvernance des données (qualité, traçabilité, sécurité).'
    ],
    tech: ['Pyspark', 'Hive', 'Postgres', 'Airflow', 'Tableau', 'Superset', 'Jira']
  }
];
---

<Section
  id="experience"
  title="Expérience Professionnelle"
  subtitle=""
>
  <div class="flex flex-col space-y-8">
    {experiences.map(({ company, logo, position, period, description, tasks = [], tech = [] }) => (
      <Card hover={true} class="w-full">
        <div class="p-6 flex flex-col h-full">
          <div class="flex items-center mb-4">
            <div class="w-12 h-12 bg-gray-100 dark:bg-gray-800 rounded-lg overflow-hidden flex items-center justify-center mr-4">
              <img src={logo} alt={company} class="w-10 h-10 object-contain" />
            </div>
            <div>
              <h3 class="font-bold text-xl">{position}</h3>
              <p class="text-sm text-gray-500 dark:text-gray-400">{company}</p>
              <p class="text-sm text-gray-500 dark:text-gray-400">{period}</p>
            </div>
          </div>

          <section class="mb-4">
            <h4 class="font-semibold text-lg mb-2">Contexte</h4>
            <p class="text-gray-600 dark:text-gray-300 text-sm">{description}</p>
          </section>

          {tasks.length > 0 && (
            <section class="mb-4">
              <h4 class="font-semibold text-lg mb-2">Travaux réalisés</h4>
              <ul class="list-disc list-inside text-gray-600 dark:text-gray-300 text-sm space-y-1">
                {tasks.map(task => <li>{task}</li>)}
              </ul>
            </section>
          )}

          {tech.length > 0 && (
            <section>
              <h4 class="font-semibold text-lg mb-2">Environnement technique</h4>
              <p class="text-gray-600 dark:text-gray-300 text-sm">{tech.join(', ')}</p>
            </section>
          )}
        </div>
      </Card>
    ))}
  </div>
</Section>
